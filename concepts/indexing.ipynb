{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a matrix of 4 latent factors for 5 users (5x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = 5\n",
    "n_factors = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "user_factors = Tensor(\n",
    "    [\n",
    "        [1, 0, 2, 1],\n",
    "        [2, 1, 3, 1],\n",
    "        [4, 2, 1, 3],\n",
    "        [2, 3, 1, 0],\n",
    "        [0, 4, 3, 1],\n",
    "    ]\n",
    ")\n",
    "assert user_factors.shape == (n_users, n_factors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For one user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And suppose we want to select the factors for user 1, the second row, using matrix multiplication so that the process can be scaled with the corresponding hardware acceleration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, turn the user index 1 into a one-hot-encoded vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_user = Tensor([0, 1, 0, 0, 0])\n",
    "assert one_hot_user.shape == (n_users,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, perform the dot product between the user factors and the one-hot-encoded user index. This will select the latent factors for that user.\n",
    "\n",
    "Normally, the dot product, which is a special case of matrix multiplication, takes two vectors of the same length and returns a scalar. But it can be performed between a matrix and a vector. The number of columns in the matrix needs to match the number of elements in the vector. The vector is implicitly treated as a column vector.\n",
    "\n",
    "`one_hot_user` has 5 elements (there are 5 users), and  `user_factors` has 5 ***rows***, because each user corresponds to a row. So we need to transpose it, then perform the product, and we will have the latent factors for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 1., 3., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors.t() @ one_hot_user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the above corresponds to the second row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For several users at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a matrix of one-hot-encoded user indices. Let's try two. First and second users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_users = Tensor(\n",
    "    [\n",
    "        [1, 0, 0, 0, 0],\n",
    "        [0, 1, 0, 0, 0],\n",
    "    ]\n",
    ")\n",
    "assert one_hot_users.shape == (2, n_users)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember our user factors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 2., 1.],\n",
       "        [2., 1., 3., 1.],\n",
       "        [4., 2., 1., 3.],\n",
       "        [2., 3., 1., 0.],\n",
       "        [0., 4., 3., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert user_factors.shape == (n_users, n_factors)\n",
    "user_factors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For matrix multiplication, the number of columns in the first matrix must equal the number of rows in the second matrix. `n_users` should be in the matching dimension in both cases. So `n_users` should correspond to the number of columns in `user_factors` (must transpose) and the number of rows in `one_hot_users` (must transpose too!).\n",
    "\n",
    "So transpose both, multiply, and behold the user factors for the first two users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [0., 1.],\n",
       "        [2., 3.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_user_factors = user_factors.t() @ one_hot_users.t()\n",
    "selected_user_factors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right. I need to tranpose the result too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 2., 1.],\n",
       "        [2., 1., 3., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_user_factors.t()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot-encoded vectors are not as efficient as using an \"embedding\", a layer that indexes into a vector using an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Wait, you can index into any matrix using a vector, no?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jargon: Embedding\n",
    "\n",
    "Multiplying by a one-hot-encoded matrix, using the computational shortcut that it can be implemented by simply indexing directly. This is quite a fancy word for a very simple concept. The thing that you multiply the one-hot-encoded matrix by (or, using the computational shortcut, index into directly) is called the embedding matrix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
